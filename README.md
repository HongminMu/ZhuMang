<img width="911" alt="A20240925" src="https://github.com/user-attachments/assets/c1397552-deb1-415a-a15f-62e2ffb39bb9" /># **Wearable Visuomotor Navigation and Mobility Assistance Device for the Partially Sighted and Visually Impaired in Unfamiliar Indoor Scenes** 👓 

<img width="911" alt="A20240925" src="https://github.com/user-attachments/assets/29a660ff-b9db-43c5-b1ed-f659231c7c18" />
 <!-- Insert a relevant image of your wearable assistive device here -->
<img width="362" alt="overall-3-14" src="https://github.com/user-attachments/assets/6d50eea8-8c48-4d67-8ae6-06e797e01793" />

## **🌟 Project Overview**  
This project, formally titled **"Wearable Visuomotor Navigation and Mobility Assistance Device for the Partially Sighted and Visually Impaired in Unfamiliar Indoor Scenes"**, enhances **mobility and independence** for visually impaired individuals by enabling **navigation in unfamiliar indoor environments without relying on dense pre-built maps**.  

🚀 **Key Features:**  
✅ **SLAM-free navigation** – Uses **Topological Semantic Mapping (TSM)** instead of conventional dense mapping.  
✅ **Text-based Localization** – Matches detected text from environmental signage with TSM nodes for precise positioning.  
✅ **Binocular Stereo Vision** – Enhances depth estimation to assist in navigation toward key landmarks.  
✅ **AI-Driven Obstacle Detection** – Uses deep learning for real-time scene awareness.  
✅ **Multi-Device Wearable Interaction** – Smart glasses process visual data, while wristbands provide haptic feedback.  

---

## **🏆 Awards & Achievements**  
This project was highly recognized in two prestigious robotics competitions:

- 🥇 **First Prize** - **World Robot Contest - Tri-Co Robots Challenge** (August 2024)  
  - **Ranked Top 3 out of 19 teams**  
  - **Project Name**: *OpenAEye: an Assistive Glasses for the Visually Impaired*  

- 🥈 **National Runner-up** - **China Graduate Robotics Innovation Design Contest** (September 2023)  
  - **Ranked 2nd out of 1,177 teams**  
  - **Project Name**: *Wearable Assistive Device for the Visually Impaired to Navigate in Unfamiliar Indoor Environments*  

---

## **🎥 Video Demonstration**  
You can download the demo videos here! *(within 25MB each)*.  
Volunteer 1
![image](https://github.com/HongminMu/ZhuMang/assets/57067148/7820972f-91ab-4a45-aa9f-684060dc663b)

Volunteer 2
<img width="1278" alt="111" src="https://github.com/user-attachments/assets/e6408f10-d5b1-4d98-bc37-b9c6c714f3fc">

[Volunteer 1](https://github.com/HongminMu/ZhuMang/blob/main/volunteer1.mp4)  
[Volunteer 2](https://github.com/HongminMu/ZhuMang/blob/main/volunteer2.mp4)

## **🚀 Code Release**  
Our code will be made publicly available soon! Stay tuned for updates. 🌍💡  

---

## **📚 Related Work**  
This work builds upon our previous research on obstacle avoidance systems for visually impaired users. Specifically, we extend our prior work on **dynamic obstacle avoidance** using **instance segmentation** to improve the **navigation experience in indoor environments**.  

You can find our previous work referenced below:  

> **Mu, Hongmin and others**, *Dynamic Obstacle Avoidance System Based on Rapid Instance Segmentation Network*, **IEEE Trans. on Intelligent Transportation Systems**, **2024**, **Vol. 25**, **No. 5**, **Pages 4578-4592**, [DOI: 10.1109/TITS.2023.3323210](https://doi.org/10.1109/TITS.2023.3323210).  

```bibtex
@ARTICLE{Mu2024Dynamic,
  author={Mu, Hongmin and Zhang, Gang and Ma, Zhe and Zhou, Mengchu and Cao, Zhengcai},
  journal={IEEE Trans. on Intelligent Transportation Systems}, 
  title={Dynamic Obstacle Avoidance System Based on Rapid Instance Segmentation Network}, 
  year={2024},
  volume={25},
  number={5},
  pages={4578-4592},
  keywords={Feature extraction;Task analysis;Collision avoidance;Real-time systems;Distance measurement;Cameras;Semantics;Obstacle avoidance;instance segmentation;mobility assistance;indoor navigation},
  doi={10.1109/TITS.2023.3323210}
}

# **Wearable Visuomotor Navigation and Mobility Assistance Device For the Partially Sighted and Visually Impaired in Unfamiliar Indoor Scenes** 👓  

![Device Image](#)  <!-- Insert a relevant image of your wearable assistive device here -->

## **🌟 Project Overview**  
This project, formally titled **"Wearable Visuomotor Navigation and Mobility Assistance Device for the Partially Sighted and Visually Impaired in Unfamiliar Indoor Scenes"**, enhances **mobility and independence** for visually impaired individuals by enabling **navigation in unfamiliar indoor environments without relying on dense pre-built maps**.  

🚀 **Key Features:**  
✅ **SLAM-free navigation** – Uses **Topological Semantic Mapping (TSM)** instead of conventional dense mapping.  
✅ **Text-based Localization** – Matches detected text from environmental signage with TSM nodes for precise positioning.  
✅ **Binocular Stereo Vision** – Enhances depth estimation to assist in navigation toward key landmarks.  
✅ **AI-Driven Obstacle Detection** – Uses deep learning for real-time scene awareness.  
✅ **Multi-Device Wearable Interaction** – Smart glasses process visual data, while wristbands provide haptic feedback.  
✅ **Semantic Elevation Map** – Incorporates a semantic elevation map to help users perceive stairs and other obstacles in real-time.  
✅ **Haptic Feedback for Stair Navigation** – The wristbands provide **vibrational feedback** to guide visually impaired users safely when navigating stairs.

---

## **🏆 Awards & Achievements**  
This project was highly recognized in two prestigious robotics competitions:

- 🥇 **First Prize** - **World Robot Contest - Tri-Co Robots Challenge** (August 2024)  
  - **Ranked Top 3 out of 19 teams**  
  - **Project Name**: *OpenAEye: an Assistive Glasses for the Visually Impaired*  

- 🥈 **National Runner-up** - **China Graduate Robotics Innovation Design Contest** (September 2023)  
  - **Ranked 2nd out of 1,177 teams**  
  - **Project Name**: *Wearable Assistive Device for the Visually Impaired to Navigate in Unfamiliar Indoor Environments*  

---

## **🎥 Video Demonstration**  
You can download the demo videos here! *(within 25MB each)*.  

## **🚀 Code Release**  
Our code will be made publicly available soon! Stay tuned for updates. 🌍💡  

---

## **📚 Related Work**  
This work builds upon our previous research on obstacle avoidance systems for visually impaired users. Specifically, we extend our prior work on **dynamic obstacle avoidance** using **instance segmentation** to improve the **navigation experience in indoor environments**.  

You can find our previous work referenced below:  

> **Mu, Hongmin and others**, *Dynamic Obstacle Avoidance System Based on Rapid Instance Segmentation Network*, **IEEE Trans. on Intelligent Transportation Systems**, **2024**, **Vol. 25**, **No. 5**, **Pages 4578-4592**, [DOI: 10.1109/TITS.2023.3323210](https://doi.org/10.1109/TITS.2023.3323210).  

```bibtex
@ARTICLE{Mu2024Dynamic,
  author={Mu, Hongmin and Zhang, Gang and Ma, Zhe and Zhou, Mengchu and Cao, Zhengcai},
  journal={IEEE Trans. on Intelligent Transportation Systems}, 
  title={Dynamic Obstacle Avoidance System Based on Rapid Instance Segmentation Network}, 
  year={2024},
  volume={25},
  number={5},
  pages={4578-4592},
  keywords={Feature extraction;Task analysis;Collision avoidance;Real-time systems;Distance measurement;Cameras;Semantics;Obstacle avoidance;instance segmentation;mobility assistance;indoor navigation},
  doi={10.1109/TITS.2023.3323210}
}
